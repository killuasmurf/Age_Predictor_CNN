{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6101211b",
   "metadata": {},
   "source": [
    "Age and Gender Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import warnings\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# import tensorflow and keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array, load_img, array_to_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
    "from keras.layers import Dropout, Input, Add, Dense, Activation, Rescaling,\\\n",
    "    BatchNormalization, Flatten, Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, Sequential, load_model\n",
    "print(dir(keras))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eb1f17",
   "metadata": {},
   "source": [
    "### 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9accca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import your custom data loading module\n",
    "# (Make sure data_loader.py is in the same folder as this notebook)\n",
    "from data_loader import get_unified_dataset\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# --- 2. Download Datasets (Only if missing) ---\n",
    "dataset_folder = './datasets'\n",
    "datasets = [\n",
    "    'jangedoo/utkface-new',\n",
    "    'ttungl/adience-benchmark-gender-and-age-classification',\n",
    "    'aiolapo/fgnet-dataset',\n",
    "    'moritzm00/biometrically-filtered-famous-figure-dataset'\n",
    "]\n",
    "\n",
    "# Authenticate with Kaggle\n",
    "if not os.getenv(\"KAGGLE_KEY\"):\n",
    "    print(\"‚ö†Ô∏è Error: KAGGLE_KEY not found. Please check your .env file.\")\n",
    "else:\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    \n",
    "    if not os.path.exists(dataset_folder):\n",
    "        os.makedirs(dataset_folder)\n",
    "\n",
    "    # Simple check: If folder is empty or barely populated, download everything\n",
    "    # (Adjust this logic if you want to be more specific per dataset)\n",
    "    if len(os.listdir(dataset_folder)) < 10:  # If less than 10 subfolders, assume datasets are missing\n",
    "        print(\"üìÇ Downloading datasets from Kaggle... this may take a while.\")\n",
    "        for dataset in datasets:\n",
    "            print(f\"   --> Downloading {dataset}...\")\n",
    "            api.dataset_download_files(dataset, path=dataset_folder, unzip=True)\n",
    "        print(\"‚úÖ Download complete!\")\n",
    "    else:\n",
    "        print(\"‚úÖ Datasets already downloaded.\")\n",
    "\n",
    "# --- 3. Load & Unify Data ---\n",
    "print(\"üîÑ Processing and loading data...\")\n",
    "df = get_unified_dataset(dataset_folder)\n",
    "\n",
    "# --- 4. Verify Data ---\n",
    "print(f\"\\nTotal Images Loaded: {len(df)}\")\n",
    "print(\"Source Breakdown:\")\n",
    "print(df['source'].value_counts())\n",
    "\n",
    "df.to_csv('datasets/df_first.csv', index=False)\n",
    "\n",
    "# Show sample\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac22cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Files in ./datasets:\", os.listdir('./datasets'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf8964a",
   "metadata": {},
   "source": [
    "### 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77bcfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/df_first.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e60e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c6a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into 2 dfs for age and gender\n",
    "df_age = df[['image_path', 'age', 'source']]\n",
    "df_age = df_age[df_age['age'] > 0]\n",
    "df_age = df_age[df_age['age'] <= 100]\n",
    "\n",
    "df_gender = df[['image_path', 'gender', 'source']]\n",
    "df_gender = df_gender[df_gender['gender'].isin([0, 1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4257a9fe",
   "metadata": {},
   "source": [
    "*Convert gender to Male and Female labels/categories*\n",
    "\n",
    "remember to comment out the labelling process so it wont convert again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a42f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].astype('category')\n",
    "\n",
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceae13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.histplot(data=df_age, x=\"age\", ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4470f6b9",
   "metadata": {},
   "source": [
    "Gender Distribution is quite balanced. However, the age distribution is highly imbalanced and heavily skewed towards younger individuals. The histogram reveals a significant peak of data points in the 20-30 year-old range, representing the majority of the dataset. This data imbalance is a critical factor that needs to be addressed before training the CNN model.\n",
    "\n",
    "**Impact on the CNN Model:**\n",
    "\n",
    "The model is highly likely to become biased towards the heavily represented age groups (e.g., 20s and 30s). This will lead to excellent prediction accuracy for these ages but poor generalization and significant performance degradation on underrepresented age groups, particularly for older individuals. The model will struggle to accurately predict the age of individuals in these categories, often defaulting to a more common age from the training set.\n",
    "\n",
    "Hence, it is crucial to implement data balancing techniques such as oversampling the minority classes, undersampling the majority classes, or using weighted loss functions during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = sorted(df['source'].dropna().unique())\n",
    "fig, axes = plt.subplots(len(sources), 2, figsize=(12, 4 * len(sources)))\n",
    "axes = np.atleast_2d(axes)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "    warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "    for i, source in enumerate(sources):\n",
    "        subset = df[df['source'] == source]\n",
    "\n",
    "        sns.histplot(subset['age'], bins=40, kde=True, ax=axes[i, 0], color='royalblue')\n",
    "        axes[i, 0].set_title(f\"ages for {source.upper()} (Count: {len(subset)})\", fontsize=12, fontweight='bold')\n",
    "        axes[i, 0].set_xlabel(\"Age\")\n",
    "        axes[i, 0].set_ylabel(\"Number of Images\")\n",
    "        axes[i, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "        sns.countplot(x='gender', data=subset, ax=axes[i, 1], palette='pastel', order=[0, 1])\n",
    "        axes[i, 1].set_title(f\"gender for {source.upper()}\", fontsize=12, fontweight='bold')\n",
    "        axes[i, 1].set_xticklabels(['Male (0)', 'Female (1)'])\n",
    "        axes[i, 1].set_xlabel(\"\")\n",
    "        axes[i, 1].set_ylabel(\"Count\")\n",
    "        for container in axes[i, 1].containers:\n",
    "            axes[i, 1].bar_label(container)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcaad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Sample 10000 images to check (much faster than checking all)\n",
    "# If you want to check everything, remove .sample(1000)\n",
    "sample_df = df.sample(n=10000, random_state=42)\n",
    "\n",
    "widths = []\n",
    "heights = []\n",
    "ratios = []\n",
    "\n",
    "print(\"Measuring 10000 random images...\")\n",
    "\n",
    "for img_path in sample_df['image_path']:\n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            w, h = img.size\n",
    "            widths.append(w)\n",
    "            heights.append(h)\n",
    "            ratios.append(w / h)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# --- Visualizing the Results ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Width vs Height\n",
    "axes[0].scatter(widths, heights, alpha=0.5, color='purple')\n",
    "axes[0].set_title(\"Image Dimensions (Width vs Height)\")\n",
    "axes[0].set_xlabel(\"Width (px)\")\n",
    "axes[0].set_ylabel(\"Height (px)\")\n",
    "axes[0].axvline(200, color='red', linestyle='--', label='Target Size (200)')\n",
    "axes[0].axhline(200, color='red', linestyle='--')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot 2: Aspect Ratio Distribution\n",
    "# Ratio = 1.0 is Square. >1 is Wide, <1 is Tall.\n",
    "sns.histplot(ratios, bins=30, ax=axes[1], color='orange', kde=True)\n",
    "axes[1].set_title(\"Aspect Ratio Distribution (Width / Height)\")\n",
    "axes[1].set_xlabel(\"Aspect Ratio (1.0 = Square)\")\n",
    "axes[1].axvline(1.0, color='black', linestyle='--', label='Perfect Square')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Summary Stats\n",
    "print(f\"Average Size: {int(np.mean(widths))}x{int(np.mean(heights))}\")\n",
    "print(f\"Smallest Width: {np.min(widths)}\")\n",
    "print(f\"Percentage of non-square images: {np.mean(np.array(ratios) != 1.0) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88e017c",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing: Balancing Dataset\n",
    "   - **Upsample** underrepresented age groups (rare ages with few samples).\n",
    "   - **Downsample** overrepresented age groups (common ages with too many samples).\n",
    "   - This helps prevent the model from overfitting to frequent ages and improves performance on rare ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bb266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_counts = df_age['age'].value_counts().sort_values()\n",
    "for i in range(100):\n",
    "    if i not in age_counts.index:\n",
    "        print(i)\n",
    "print(age_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6503d138",
   "metadata": {},
   "source": [
    "I will need to find images for 94, 97, 98 and upsample 5 more for them. And then downsample all ages to just 2k images, in order to balance the age distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1d0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step is for creating augmented images for missing ages (94, 97, 98)\n",
    "# These will be created by the augmentation loop below\n",
    "# For now, we'll let the augmentation script handle this\n",
    "\n",
    "# Remove this code block - we'll get these images from the augmentation process\n",
    "# new_rows = pd.DataFrame({\n",
    "#     'age': [94, 97, 98],\n",
    "#     'image_path': [Path('UTKFace_augmented/age_94_lady.jpg'), Path('UTKFace_augmented/age_97_lady.jpg'), Path('UTKFace_augmented/age_97_lady.jpg')],\n",
    "#     'source': ['augmented', 'augmented', 'augmented']\n",
    "# })\n",
    "\n",
    "# df_age = pd.concat([df_age, new_rows], ignore_index=True, sort=False)\n",
    "# df_age.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2839761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Augmentation Strategy\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,  # Randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1,  # Randomly translate images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # Randomly translate images vertically (fraction of total height)\n",
    "    brightness_range=[0.8, 1.2],  # Randomly change brightness\n",
    "    shear_range=0.1,  # Shear angle in counter-clockwise direction in degrees\n",
    "    zoom_range=0.1, # Randomly zoom in on images\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de05dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder for augmented images\n",
    "augmented_path = Path(\"datasets/UTKFace_augmented\")\n",
    "augmented_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b086372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for images to augment that actually exist\n",
    "# First check what data we have\n",
    "age_counts = df_age['age'].value_counts().sort_values()\n",
    "print(\"Ages with fewer than 5 images:\")\n",
    "missing_or_rare_ages = age_counts[age_counts < 10].index.tolist()\n",
    "print(missing_or_rare_ages)\n",
    "\n",
    "# Filter to only augment ages that actually have source images\n",
    "target_ages = [age for age in missing_or_rare_ages if len(df_age[df_age['age'] == age]) > 0]\n",
    "print(f\"\\nTarget ages for augmentation (with existing images): {target_ages}\")\n",
    "\n",
    "subset = df_age[df_age['age'].isin(target_ages)]\n",
    "print(f\"Found {len(subset)} images to augment\")\n",
    "print(subset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in subset.iterrows():\n",
    "    original_img_path = Path(f\"{row.image_path}\")\n",
    "    \n",
    "    # Extract just the filename without extension\n",
    "    original_filename = original_img_path.stem  # e.g., \"image\" from \"image.jpg\"\n",
    "    \n",
    "    try:\n",
    "        # Load the image\n",
    "        img = Image.open(original_img_path)\n",
    "        img_array = np.array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        i = 0\n",
    "        for batch in datagen.flow(img_array, batch_size=1):\n",
    "            augmented_image_array = batch[0]\n",
    "            augmented_image = array_to_img(augmented_image_array)\n",
    "            \n",
    "            # Create filename with _augmented suffix\n",
    "            augmented_filename = f\"{original_filename}_{row['age']}_augmented_{i}.jpg\"\n",
    "            augmented_image_path = augmented_path / augmented_filename\n",
    "            augmented_image.save(augmented_image_path)\n",
    "            print(f\"Saved augmented image: {augmented_image_path}\")\n",
    "            \n",
    "            # Add to df_age immediately\n",
    "            new_row = pd.DataFrame({\n",
    "                'image_path': [augmented_image_path],\n",
    "                'age': [row['age']],\n",
    "                'source': ['augmented']\n",
    "            })\n",
    "            df_age = pd.concat([df_age, new_row], ignore_index=True)\n",
    "            \n",
    "            i += 1\n",
    "            if i >= 2:\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {original_img_path}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a057041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6ebc05",
   "metadata": {},
   "source": [
    "#### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aea3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Settings ---\n",
    "MAX_IMAGES_PER_AGE = 2000\n",
    "\n",
    "# --- 2. The Logic ---\n",
    "processed_chunks = []\n",
    "unique_ages = df_age['age'].unique()\n",
    "\n",
    "print(f\"üîÑ Processing {len(unique_ages)} unique age groups...\")\n",
    "\n",
    "for age in unique_ages:\n",
    "    # Get all rows for this specific age\n",
    "    age_group = df_age[df_age['age'] == age]\n",
    "    \n",
    "    count = len(age_group)\n",
    "    \n",
    "    # Case A: Small group? Keep everything.\n",
    "    if count <= MAX_IMAGES_PER_AGE:\n",
    "        processed_chunks.append(age_group)\n",
    "        \n",
    "    # Case B: Too big? Downsample while keeping source ratios.\n",
    "    else:\n",
    "        # Calculate fraction to keep (e.g., 2000 / 4000 = 0.5)\n",
    "        frac = MAX_IMAGES_PER_AGE / count\n",
    "        \n",
    "        # We group by 'source' within this age and sample strictly.\n",
    "        # This ensures if we keep 50%, we keep 50% of UTK, 50% of Adience, etc.\n",
    "        sampled = age_group.groupby('source', group_keys=False).apply(\n",
    "            lambda x: x.sample(frac=frac, random_state=42)\n",
    "        )\n",
    "        processed_chunks.append(sampled)\n",
    "\n",
    "# --- 3. Combine Back Together ---\n",
    "# This creates a brand new clean dataframe\n",
    "df_meow = pd.concat(processed_chunks, ignore_index=True)\n",
    "\n",
    "print(\"‚úÖ Downsampling complete!\")\n",
    "print(f\"Original size: {len(df_age)}\")\n",
    "print(f\"New size:      {len(df_meow)}\")\n",
    "\n",
    "# --- 4. Verify ---\n",
    "print(\"\\nTop 5 ages by count (Should be ~2000):\")\n",
    "print(df_meow['age'].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = df_meow['age'], bins = 100, color='teal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65d253d",
   "metadata": {},
   "source": [
    "##### *Data is definitely more balanced than before.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6012704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check current type\n",
    "is_path_type = df_meow['image_path'].apply(lambda x: isinstance(x, Path)).all()\n",
    "print(f\"Current Status: Are all image_paths 'Path' objects? {is_path_type}\")\n",
    "\n",
    "# 2. FIX IT: If they are strings, convert them back to Path objects\n",
    "if not is_path_type:\n",
    "    print(\"üîÑ Converting strings to Path objects...\")\n",
    "    df_meow['image_path'] = df_meow['image_path'].apply(Path)\n",
    "    \n",
    "    # Re-check\n",
    "    is_path_type_now = df_meow['image_path'].apply(lambda x: isinstance(x, Path)).all()\n",
    "    print(f\"‚úÖ Fixed Status: Are all image_paths 'Path' objects? {is_path_type_now}\")\n",
    "else:\n",
    "    print(\"‚úÖ No changes needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600d6c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meow.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f144bb3",
   "metadata": {},
   "source": [
    "### 4. Split into response and predictor\n",
    "\n",
    "##### Data Preparation (df_meow only)\n",
    "I detect and crop faces with **YOLO-Face**, resize to **224x224**, normalize to **[0,1]**, create `df_meow[\"age_group\"]`, and prepare train/validation data for both outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# --- Constants ---\n",
    "IMAGE_SIZE = (224, 224)\n",
    "NUM_AGE_GROUPS = 5\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.15\n",
    "RANDOM_STATE = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# --- Setup Save Directory ---\n",
    "# We create a folder to save your cropped faces so you don't have to re-run YOLO later.\n",
    "save_dir = Path(\"./processed_faces\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def map_age_to_group(age):\n",
    "    # I map each raw age value to your required 5-class age group.\n",
    "    age = int(age)\n",
    "    if 0 <= age <= 12:\n",
    "        return 0  # Child\n",
    "    if 13 <= age <= 25:\n",
    "        return 1  # Youth\n",
    "    if 26 <= age <= 42:\n",
    "        return 2  # Adult\n",
    "    if 43 <= age <= 60:\n",
    "        return 3  # Middle Age\n",
    "    return 4      # Senior (60+)\n",
    "\n",
    "# --- Load YOLO Model ---\n",
    "# I download YOLO-Face weights once from Hugging Face and load the detector.\n",
    "yolo_face_weights = hf_hub_download(\n",
    "    repo_id=\"Bingsu/adetailer\",\n",
    "    filename=\"face_yolov8n.pt\"\n",
    ")\n",
    "yolo_face_model = YOLO(yolo_face_weights)\n",
    "\n",
    "def crop_face_with_yolo(image_path: Path, target_size=IMAGE_SIZE, conf_thres: float = 0.3, margin_ratio: float = 0.15):\n",
    "    # I read the image in BGR format because OpenCV loads BGR by default.\n",
    "    image_bgr = cv2.imread(str(image_path))\n",
    "    if image_bgr is None:\n",
    "        return None\n",
    "\n",
    "    # I run YOLO-Face inference and get the first result object.\n",
    "    result = yolo_face_model.predict(\n",
    "        source=image_bgr,\n",
    "        conf=conf_thres,\n",
    "        verbose=False\n",
    "    )[0]\n",
    "\n",
    "    # I safely handle the case where no face is detected.\n",
    "    if result.boxes is None or len(result.boxes) == 0:\n",
    "        return None\n",
    "\n",
    "    # Logic: It assumes the largest face belongs to the main subject \n",
    "    # and ignores the smaller background faces.\n",
    "    boxes_xyxy = result.boxes.xyxy.cpu().numpy()\n",
    "    areas = (boxes_xyxy[:, 2] - boxes_xyxy[:, 0]) * (boxes_xyxy[:, 3] - boxes_xyxy[:, 1])\n",
    "    x1, y1, x2, y2 = boxes_xyxy[np.argmax(areas)].astype(int)\n",
    "\n",
    "    # Why: YOLO bounding boxes are usually very \"tight\". \n",
    "    # Action: It expands the box by 15% (0.15) on all sides. \n",
    "    h, w = image_bgr.shape[:2]\n",
    "    bw, bh = (x2 - x1), (y2 - y1)\n",
    "    mx, my = int(bw * margin_ratio), int(bh * margin_ratio)\n",
    "\n",
    "    x1 = max(0, x1 - mx)\n",
    "    y1 = max(0, y1 - my)\n",
    "    x2 = min(w, x2 + mx)\n",
    "    y2 = min(h, y2 + my)\n",
    "\n",
    "    # Cropping the face region from the original BGR image.\n",
    "    face_bgr = image_bgr[y1:y2, x1:x2]\n",
    "    if face_bgr.size == 0:\n",
    "        return None\n",
    "\n",
    "    # I convert to RGB, resize to 224x224, and normalize to [0,1].\n",
    "    face_rgb = cv2.cvtColor(face_bgr, cv2.COLOR_BGR2RGB)\n",
    "    face_rgb = cv2.resize(face_rgb, target_size, interpolation=cv2.INTER_AREA)\n",
    "    face_rgb = face_rgb.astype(\"float32\") / 255.0\n",
    "    return face_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# --- Preparation ---\n",
    "df_meow = df_meow.dropna(subset=[\"image_path\", \"age\"]).copy()\n",
    "\n",
    "# Note: We keep age as int64 here (cleaner for you)\n",
    "df_meow[\"age_group\"] = df_meow[\"age\"].apply(map_age_to_group).astype(\"int32\")\n",
    "\n",
    "processed_metadata = []\n",
    "skipped_count = 0\n",
    "\n",
    "print(f\"üöÄ Starting Processing on {len(df_meow)} images...\")\n",
    "\n",
    "for row in tqdm(df_meow.itertuples(index=False), total=len(df_meow)):\n",
    "    image_path = Path(str(row.image_path))\n",
    "    \n",
    "    if not image_path.exists():\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "\n",
    "    # Crop\n",
    "    face = crop_face_with_yolo(image_path) # Returns uint8 (0-255)\n",
    "    if face is None:\n",
    "        skipped_count += 1\n",
    "        continue\n",
    "\n",
    "    # Save to disk\n",
    "    # Convert RGB -> BGR for OpenCV\n",
    "    face_bgr = cv2.cvtColor(face, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    save_name = f\"{int(row.age)}_{image_path.name}\"\n",
    "    save_path = save_dir / save_name\n",
    "    cv2.imwrite(str(save_path), face_bgr)\n",
    "\n",
    "    # Store Metadata\n",
    "    processed_metadata.append({\n",
    "        \"path\": str(save_path), # <--- This is the new cropped image path\n",
    "        \"age\": row.age,          # <--- Kept as int/original\n",
    "        \"age_group\": row.age_group\n",
    "    })\n",
    "\n",
    "if not processed_metadata:\n",
    "    raise ValueError(\"No images processed!\")\n",
    "\n",
    "# Create clean DataFrame\n",
    "df_processed = pd.DataFrame(processed_metadata)  # the new df with paths, age & age groups\n",
    "\n",
    "# --- FINAL CONVERSION ---\n",
    "# This is where we satisfy the model's need for floats\n",
    "X = df_processed[\"path\"].values\n",
    "y_age = df_processed[\"age\"].values.astype(\"float32\") # <--- Convert ONLY here\n",
    "y_age_group = df_processed[\"age_group\"].values.astype(\"int32\")\n",
    "\n",
    "df_processed.to_csv(\"processed_metadata.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Processed {len(X)} images. Saved to disk.\")\n",
    "print(f\"‚ö†Ô∏è Skipped {skipped_count}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7345195",
   "metadata": {},
   "source": [
    ">_Can use this cell if restarted kernel / rerun_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d10dad8",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca10e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Split Data (Train / Val / Test) ---\n",
    "\n",
    "# I verify stratification requirements quickly to ensure fair age distribution.\n",
    "stratify_vals = y_age_group if (pd.Series(y_age_group).value_counts().min() >= 2) else None\n",
    "\n",
    "# First Split: Separate the Test Set (10% of total)\n",
    "# This data is locked away and only used for the final exam.\n",
    "X_temp, X_test, y_age_temp, y_age_test, y_group_temp, y_group_test = train_test_split(\n",
    "    X, y_age, y_age_group,\n",
    "    test_size=0.10, \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=stratify_vals\n",
    ")\n",
    "\n",
    "# Recalculate stratify values for the remaining 90%\n",
    "stratify_vals_temp = y_group_temp if (pd.Series(y_group_temp).value_counts().min() >= 2) else None\n",
    "\n",
    "# Second Split: Separate Train and Validation\n",
    "# I use 0.1111 (approx 1/9) because 1/9th of the remaining 90% equals 10% of the total.\n",
    "# Final Result: Train (80%), Val (10%), Test (10%)\n",
    "X_train, X_val, y_age_train, y_age_val, y_group_train, y_group_val = train_test_split(\n",
    "    X_temp, y_age_temp, y_group_temp,\n",
    "    test_size=0.1111, \n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=stratify_vals_temp\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data Split Complete:\")\n",
    "print(f\"Train: {len(X_train)} samples (80%)\")\n",
    "print(f\"Val:   {len(X_val)} samples (10%)\")\n",
    "print(f\"Test:  {len(X_test)} samples (10%)\")\n",
    "\n",
    "# --- 2. Dataset Pipeline ---\n",
    "\n",
    "def load_and_process_image(path, targets):\n",
    "    \"\"\"Loads image from disk, decodes, resizes, and normalizes.\"\"\"\n",
    "    # I read the raw file from the disk\n",
    "    img = tf.io.read_file(path)\n",
    "    # I decode the compressed string into a tensor\n",
    "    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
    "    # I resize it because the model expects a fixed 224x224 input\n",
    "    img = tf.image.resize(img, IMAGE_SIZE)\n",
    "    # I normalize pixels from 0-255 to 0-1 for faster convergence\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img, targets\n",
    "\n",
    "def make_dataset(paths, age_targets, group_targets, training=False):\n",
    "    # I create the base dataset from paths (Strings) and labels\n",
    "    ds = tf.data.Dataset.from_tensor_slices((\n",
    "        paths,\n",
    "        { \"age_group_output\": group_targets, \"age_output\": age_targets }\n",
    "    ))\n",
    "\n",
    "    # ‚ö†Ô∏è CRITICAL STEP: Map paths -> Actual Images\n",
    "    # num_parallel_calls=AUTOTUNE allows my CPU to load multiple images while the GPU trains\n",
    "    ds = ds.map(load_and_process_image, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    # I only shuffle the training data. \n",
    "    # Validation and Test order should stay fixed for consistent evaluation.\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=1000, seed=RANDOM_STATE)\n",
    "\n",
    "    # I batch the images and prefetch the next batch to avoid bottlenecks\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# --- 3. Create Datasets ---\n",
    "# I create optimized pipelines for all three sets.\n",
    "# Note: training=True only for the training set!\n",
    "train_ds = make_dataset(X_train, y_age_train, y_group_train, training=True)\n",
    "val_ds   = make_dataset(X_val,   y_age_val,   y_group_val,   training=False)\n",
    "test_ds  = make_dataset(X_test,  y_age_test,  y_group_test,  training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0c223e",
   "metadata": {},
   "source": [
    "#### 5. Build & Compile the Model - Architecture: EfficientNetB0 Backbone\n",
    "\n",
    "Instead of building a custom CNN from scratch, I use **Transfer Learning** with a pre-trained EfficientNetB0 backbone.\n",
    "\n",
    "##### **EfficientNetB0 (Pre-trained) ‚Üí GlobalAveragePooling ‚Üí Dense(Shared) ‚Üí Split Heads**\n",
    "\n",
    "1. **EfficientNetB0 Backbone (The \"Eye\"):**\n",
    "   - **Why use it?** Unlike my custom CNN which learns from random weights, this model has already been trained on **14 million images** (ImageNet). It already knows how to detect edges, textures, and shapes.\n",
    "   - **Benefit:** Massive improvement in feature extraction without needing millions of face images.\n",
    "\n",
    "2. **Freezing the Backbone (Stage 1 Strategy):**\n",
    "- I set backbone.trainable = False.\n",
    "\n",
    "- Why? The new layers at the end have random weights. If I trained everything at once, these random errors would propagate back and destroy the pre-trained ImageNet patterns. I keep the backbone \"frozen\" first to let the new layers learn to work with it.\n",
    "\n",
    "3. **GlobalAveragePooling2D:**\n",
    "   - Replaces `Flatten`. Instead of keeping every pixel location, it averages the features map. \n",
    "   - **Benefit:** Drastically reduces the number of parameters, preventing overfitting and making the model smaller/faster.\n",
    "\n",
    "4. **Shared Dense Layer (256 units + ReLU):**\n",
    "   - Combines the high-level features extracted by EfficientNet into a vector representing the face.\n",
    "   - **Dropout (Tunable):** Randomly turns off neurons to force the model to learn robust features, preventing it from relying on just one specific visual cue.\n",
    "\n",
    "5. **Two-Head Output Strategy (Multi-Task Learning):**\n",
    "   - **Head 1 (Classification):** `Softmax` output for Age Group. Acts as an \"anchor\" to guide the model towards the general correct range.\n",
    "   - **Head 2 (Regression):** `Linear` output for Exact Age. Fine-tunes the prediction to get the specific number.\n",
    "   - **Why?** Learning both tasks simultaneously improves the shared backbone features, making the model smarter than if it learned just one.\n",
    "\n",
    "6. **Compile the model:**\n",
    "\n",
    "> _It prepares your model for training by telling it:_\n",
    "1) _How to learn (optimizer)_   = I use `adam` since it is the best choice for beginners and most practical models\n",
    "2) _What to measure (metrics)_ \n",
    "3) _What to minimize (loss function)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1796722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "def build_tunable_model(hp):\n",
    "    # I define the hyperparameter search space.\n",
    "    # 1. Dropout: Controls how much \"memory\" we delete to prevent overfitting.\n",
    "    dropout_rate = hp.Float(\"dropout_rate\", min_value=0.25, max_value=0.35, step=0.05)\n",
    "    \n",
    "    # 2. Learning Rate: Controls how fast the model learns. \n",
    "    # Too fast = unstable; Too slow = takes forever.\n",
    "    lr = hp.Choice(\"learning_rate\", values=[1e-3, 5e-4, 1e-4])\n",
    "\n",
    "    # --- Input & Backbone ---\n",
    "    # I define the input shape explicitly.\n",
    "    inputs = Input(shape=(224, 224, 3), name=\"image_input\")\n",
    "    \n",
    "    # EfficientNet expects [0, 255] pixels, but we normalized to [0, 1].\n",
    "    # I rescale the inputs back to [0, 255] internally.\n",
    "    x = Rescaling(255.0)(inputs)\n",
    "\n",
    "    # I load the pre-trained EfficientNetB0.\n",
    "    # pooling=\"avg\" automatically applies GlobalAveragePooling2D.\n",
    "    backbone = EfficientNetB0(\n",
    "        include_top=False, \n",
    "        weights=\"imagenet\", \n",
    "        input_shape=(224, 224, 3), \n",
    "        pooling=\"avg\"\n",
    "    )\n",
    "    \n",
    "    # I freeze the backbone so we don't destroy the pre-trained ImageNet weights \n",
    "    # while our new custom heads are initialized randomly.\n",
    "    backbone.trainable = False\n",
    "    \n",
    "    # I extract the features using the frozen backbone.\n",
    "    features = backbone(x, training=False)\n",
    "\n",
    "    # --- Shared Layers ---\n",
    "    # I combine features into a shared dense layer.\n",
    "    shared = Dense(256, activation=\"relu\", name=\"shared_dense\")(features)\n",
    "    shared = Dropout(dropout_rate, name=\"shared_dropout\")(shared)\n",
    "\n",
    "    # --- Output Heads ---\n",
    "    # Head 1: Age Group (Helper Task)\n",
    "    age_group_output = Dense(NUM_AGE_GROUPS, activation=\"softmax\", name=\"age_group_output\")(shared)\n",
    "    \n",
    "    # Head 2: Exact Age (Main Task)\n",
    "    age_output = Dense(1, activation=\"linear\", name=\"age_output\")(shared)\n",
    "\n",
    "    # --- Compile ---\n",
    "    model = Model(inputs=inputs, outputs=[age_group_output, age_output])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "        loss={\n",
    "            \"age_group_output\": \"sparse_categorical_crossentropy\",\n",
    "            \"age_output\": \"mean_absolute_error\"\n",
    "        },\n",
    "        loss_weights={\n",
    "            \"age_group_output\": 0.5, # Auxiliary weight (Guide)\n",
    "            \"age_output\": 1.0        # Primary weight (Goal)\n",
    "        },\n",
    "        metrics={\n",
    "            \"age_group_output\": \"accuracy\", \n",
    "            \"age_output\": \"mae\"\n",
    "        }\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Model Architecture defined successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e207db3d",
   "metadata": {},
   "source": [
    "#### 6. Hyperparameter Search (Tuning)\n",
    "\n",
    "I use **Keras Tuner (Hyperband)** to automatically find the best configuration.\n",
    "\n",
    "**What I am searching for:**\n",
    "1.  **Dropout Rate:** (0.2, 0.3, 0.4, 0.5) - To find the perfect balance for regularization.\n",
    "2.  **Initial Learning Rate:** (0.001, 0.0005, 0.0001) - To find the best speed to start training.\n",
    "\n",
    "**Callbacks used during search:**\n",
    "- **EarlyStopping:** Stops bad trials immediately to save time.\n",
    "- **ReduceLROnPlateau:** If a trial gets stuck, it lowers the learning rate to try and squeeze out better performance. This ensures every configuration gets a fair chance to reach its best potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef7b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "# I initialize the Hyperband tuner.\n",
    "tuner = kt.Hyperband(\n",
    "    build_tunable_model,\n",
    "    objective=kt.Objective(\"val_age_output_mae\", direction=\"min\"),\n",
    "    max_epochs=15,\n",
    "    factor=3,\n",
    "    directory=\"efficientnet_tuning\",\n",
    "    project_name=\"age_tuning_final\"\n",
    ")\n",
    "\n",
    "# --- Define Callbacks ---\n",
    "# 1. Stop trials that are not improving to save time.\n",
    "# removed since it can be too aggressive for tuning and may stop promising trials early.\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_age_output_mae', \n",
    "    patience=2, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 2. Reduce Learning Rate if the model hits a plateau.\n",
    "# This helps each trial converge better, making the comparison fairer.\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_age_output_mae', \n",
    "    factor=0.2,    # Reduce LR to 20% of its value\n",
    "    patience=1,    # Wait just 1 epoch (aggressive for tuning)\n",
    "    mode = 'min',\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting Hyperparameter Search...\")\n",
    "\n",
    "# I run the search with only stop_early callback.\n",
    "tuner.search(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=[reduce_lr]  # remove stop_early\n",
    ")\n",
    "\n",
    "# --- Retrieve Results ---\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\\nüèÜ Best Hyperparameters Found:\")\n",
    "print(f\"   - Dropout Rate: {best_hps.get('dropout_rate')}\")\n",
    "print(f\"   - Initial Learning Rate: {best_hps.get('learning_rate')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a32cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "print(best_trial.metrics.get_history(\"val_age_output_mae\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53074379",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(..., epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accfe5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Show the top 10 trials\n",
    "# This prints a table showing which combinations won and their validation scores.\n",
    "print(\"\\nüìä TOP 5 TRIALS SUMMARY:\")\n",
    "tuner.results_summary(num_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e874e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Get the Best Trial ---\n",
    "best_trial = tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "\n",
    "# --- 2. Extract Validation Metrics ---\n",
    "val_mae = best_trial.score  # This is the objective\n",
    "val_loss = best_trial.metrics.get_last_value(\"val_loss\")\n",
    "\n",
    "# Safe retrieval (in case metric names differ)\n",
    "def safe_get(metric_name):\n",
    "    try:\n",
    "        return best_trial.metrics.get_last_value(metric_name)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "val_acc = safe_get(\"val_age_group_output_accuracy\")\n",
    "train_loss = safe_get(\"loss\")\n",
    "train_mae = safe_get(\"age_output_mae\")\n",
    "train_acc = safe_get(\"age_group_output_accuracy\")\n",
    "\n",
    "# --- 3. Print Report ---\n",
    "print(f\"üèÜ BEST TRIAL ID: {best_trial.trial_id}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(f\"üìâ Validation MAE (Objective): {val_mae:.4f}\")\n",
    "print(f\"üìâ Validation Loss:            {val_loss:.4f}\")\n",
    "\n",
    "if val_acc is not None:\n",
    "    print(f\"‚úÖ Validation Accuracy:        {val_acc:.4f}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if train_loss is not None:\n",
    "    print(f\"üìâ Training Loss:              {train_loss:.4f}\")\n",
    "\n",
    "if train_mae is not None:\n",
    "    print(f\"üìâ Training MAE:               {train_mae:.4f}\")\n",
    "\n",
    "if train_acc is not None:\n",
    "    print(f\"‚úÖ Training Accuracy:          {train_acc:.4f}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"Hyperparameters:\")\n",
    "print(best_trial.hyperparameters.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d138baaf",
   "metadata": {},
   "source": [
    "#### 7. Fine-Tuning (Stage 2: Unfreezing)\n",
    "\n",
    "Now that the Tuner has found the best architecture (Dropout/Learning Rate) and trained the classification heads, I unfreeze the **EfficientNet backbone**.\n",
    "\n",
    "**Strategy:**\n",
    "1.  **Unfreeze Top Layers:** I unfreeze the top ~40 layers of the backbone.\n",
    "2.  **Low Learning Rate (1e-5):** I use a very small learning rate to gently adapt the pre-trained weights to face features without \"forgetting\" the general shapes learned from ImageNet.\n",
    "3.  **Early Stopping:** I set a higher epoch limit (20) but rely on Early Stopping to halt training once the model stops improving.\n",
    "\n",
    "This step transforms the model from a generic image classifier into a specialized **Face Age Predictor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b330cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "FINE_TUNE_EPOCHS = 30    # Increased to 20 as a safety buffer (EarlyStopping will cut it short)\n",
    "FINE_TUNE_LR = 1e-5      # Ultra-low LR to prevent destroying pre-trained weights\n",
    "UNFREEZE_TOP_LAYERS = 40 # Only let the top ~2 blocks of EfficientNet learn\n",
    "\n",
    "# 1. Retrieve the Best Model from the Tuner (It's already trained on Stage 1)\n",
    "# Note: The tuner returns a COMPILED model, but we must recompile it later anyway.\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# 2. Locate the Backbone Layer\n",
    "# I find the layer named \"efficientnetb0\" dynamically because its name might vary slightly.\n",
    "backbone = next(layer for layer in best_model.layers if \"efficientnet\" in layer.name.lower())\n",
    "\n",
    "# 3. Unfreeze the Backbone (Master Switch ON)\n",
    "backbone.trainable = True\n",
    "\n",
    "# 4. Freeze the Bottom Layers (Keep low-level features static)\n",
    "# I lock the first ~200 layers so we only refine the high-level features at the top.\n",
    "for layer in backbone.layers[:-UNFREEZE_TOP_LAYERS]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"üîì Unfrozen top {UNFREEZE_TOP_LAYERS} layers. Ready for Fine-Tuning.\")\n",
    "\n",
    "# 5. Recompile (CRITICAL STEP)\n",
    "# You MUST recompile to apply the \"trainable=True\" changes and set the new Low LR.\n",
    "best_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=FINE_TUNE_LR),\n",
    "    loss={\n",
    "        \"age_group_output\": \"sparse_categorical_crossentropy\",\n",
    "        \"age_output\": \"mean_absolute_error\"\n",
    "    },\n",
    "    loss_weights={\n",
    "        \"age_group_output\": 0.5, # Helper task (Guide)\n",
    "        \"age_output\": 1.0        # Main task (Goal)\n",
    "    },\n",
    "    metrics={\"age_group_output\": \"accuracy\", \"age_output\": \"mae\"}\n",
    ")\n",
    "\n",
    "# 6. Define Callbacks for Safety\n",
    "callbacks_fine_tune = [\n",
    "    # Stop if validation MAE doesn't improve for 4 epochs\n",
    "    # This acts as the real \"Epoch Limit\"\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_age_output_mae\", \n",
    "        mode=\"min\", \n",
    "        patience=4, \n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    # If stuck, lower the LR even more (to 1e-7)\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_age_output_mae\", \n",
    "        mode=\"min\", \n",
    "        factor=0.5, \n",
    "        patience=2, \n",
    "        min_lr=1e-7, \n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9375e0e5",
   "metadata": {},
   "source": [
    "üü¢ Age Prediction Metrics (regression)\n",
    "| Metric             | Meaning                                                   |\n",
    "| ------------------ | --------------------------------------------------------- |\n",
    "| `age_output_loss`  | Mean Squared Error (how off the predictions are, squared) |\n",
    "| `age_output_mae`   | Mean Absolute Error (average error in years)              |\n",
    "| `val_age_output_` | Same as above, but on validation set (unseen data)        |\n",
    "\n",
    "üü¢ Gender Prediction Metrics (classification)\n",
    "| Metric                       | Meaning                                                      |\n",
    "| ---------------------------- | ------------------------------------------------------------ |\n",
    "| `gender_output_accuracy`     | % of genders predicted correctly on training data            |\n",
    "| `val_gender_output_accuracy` | Same for validation (unseen) data                            |\n",
    "| `gender_output_loss`         | How wrong the model was on predicting gender (cross-entropy) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8bddbd",
   "metadata": {},
   "source": [
    "‚úÖ What we can conclude:\n",
    "\n",
    "1) Model is learning age and gender well\n",
    "- MAE dropped from 7.8901 ‚Üí 5.7301 on training\n",
    "- Validation MAE dropped from 11.1618 ‚Üí 8.4502\n",
    "\n",
    "- Gender training accuracy went from 86.46% ‚Üí 94.58%\n",
    "- Validation accuracy stayed strong: ~ 86%‚Äì88%\n",
    "\n",
    "2) **No severe overfitting** - Training and validation accuracy/MAE **stay close**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb6d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Starting Stage 2 Training (Fine-Tuning)...\")\n",
    "\n",
    "# 7. Train\n",
    "history_fine = best_model.fit(\n",
    "    train_ds,                  # Dataset handles inputs automatically\n",
    "    validation_data=val_ds,    # Dataset handles validation\n",
    "    epochs=FINE_TUNE_EPOCHS,\n",
    "    callbacks=callbacks_fine_tune,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ef1b9",
   "metadata": {},
   "source": [
    "### 8. Save the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c20c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(\"age_prediction_model_final.h5\")\n",
    "print(\"Final Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68766ee",
   "metadata": {},
   "source": [
    "#### 9. Model Evaluation & Performance Visualization\n",
    "\n",
    "Now that training is complete, I evaluate the final model on the **Test Set**‚Äîdata it has never seen before. \n",
    "\n",
    "I also plot the training curves for the fine-tuning stage to check for:\n",
    "1. **Convergence:** Did the MAE actually go down?\n",
    "2. **Overfitting:** Is there a huge gap between Training and Validation performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Evaluate on Test Set ---\n",
    "# We use the test_ds we created earlier, which is optimized for CPU/GPU efficiency.\n",
    "print(\"üìä Evaluating on Test Set...\")\n",
    "results = best_model.evaluate(test_ds, verbose=1)\n",
    "\n",
    "# Mapping results to names (Model returns: loss, group_loss, age_loss, group_acc, age_mae)\n",
    "# Note: The order depends on your model.metrics_names\n",
    "metrics_map = dict(zip(best_model.metrics_names, results))\n",
    "\n",
    "print(f\"\\nüìà Final Test Results:\")\n",
    "print(f\"   - Age Mean Absolute Error (MAE): {metrics_map['age_output_mae']:.2f} years\")\n",
    "print(f\"   - Age Group Accuracy: {metrics_map['age_group_output_accuracy']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be267dd",
   "metadata": {},
   "source": [
    "- 98.73,         # Total combined loss\n",
    "- 97.55,         # Age prediction loss (MSE)\n",
    "- 0.8378,        # Gender prediction loss (Cross-Entropy)\n",
    "- 7.55,          # Age prediction MAE (Mean Absolute Error)\n",
    "- 0.8784         # Gender prediction accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a802c39",
   "metadata": {},
   "source": [
    "#### 10. Plotting of training history\n",
    "<br> \n",
    "\n",
    "#### Training and Validation Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We use 'history_fine' from our Stage 2 training\n",
    "h = history_fine.history\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# --- Plot 1: Age MAE (Regression) ---\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(h['age_output_mae'], label='Train MAE', color='blue', linestyle='--')\n",
    "plt.plot(h['val_age_output_mae'], label='Val MAE', color='blue', linewidth=2)\n",
    "plt.title('Age Prediction: Mean Absolute Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE (Years)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Plot 2: Age Group Accuracy (Classification) ---\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(h['age_group_output_accuracy'], label='Train Acc', color='green', linestyle='--')\n",
    "plt.plot(h['val_age_group_output_accuracy'], label='Val Acc', color='green', linewidth=2)\n",
    "plt.title('Age Group: Classification Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c897da5d",
   "metadata": {},
   "source": [
    "#### 1. Age Prediction (Mean Absolute Error)\n",
    "\n",
    "üîµ Train MAE steadily decreased from ~7.8 to ~5.7 years, showing that my model is consistently learning from the training data.\n",
    "\n",
    "üü† Validation MAE is more unstable, with spikes (up to ~18) around epoch 6, before settling between 7‚Äì9 years.\n",
    "\n",
    "My takeaway:\n",
    "\n",
    "- The training curve looks healthy, but the validation curve shows signs of overfitting and instability.\n",
    "\n",
    "- My model may be memorizing training examples too well while struggling to generalize to unseen data.\n",
    "\n",
    "- To improve, I could try Regularization (e.g., L2 weight decay) and more data augmentation.\n",
    "\n",
    "#### 2. Gender Prediction (Accuracy)\n",
    "\n",
    "üîµ Train Accuracy improved smoothly, reaching ~94.5%.\n",
    "\n",
    "üü† Validation Accuracy fluctuated between 83‚Äì89%, without the same steady upward trend.\n",
    "\n",
    "My takeaway:\n",
    "\n",
    "The gap between training and validation accuracy suggests overfitting. My model performs very well on the training set but struggles to maintain stable accuracy on validation.\n",
    "\n",
    "Possible improvements: Add dropout in convolutional layers (not just at the dense layer). Tune batch size or try early stopping with patience to prevent over-training.\n",
    "\n",
    "#### ‚úÖ Overall Reflection\n",
    "\n",
    "Age prediction has promising training results but unstable validation MAE, pointing to generalization issues.\n",
    "\n",
    "Gender prediction shows high training accuracy but fluctuating validation performance, another sign of overfitting.\n",
    "\n",
    "I‚Äôm happy with the direction my model is going (it clearly learns useful patterns), but I recognize I need to work on improving generalization so that it performs more reliably on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3967e66f",
   "metadata": {},
   "source": [
    "#### 11. Build a new CNN Model - Improve Generatlization\n",
    "\n",
    "##### To solve my overfitting issues:\n",
    "1) Use a joint objective in my keras tuning, and change objectives to increase accuracy on validation dataset instead, since training accuracy will usually go up anyways.\n",
    "2) Add L2 regularization with tuning, to pick optimal regularization as well as Learning Rate\n",
    "3) Add EarlyStoppiong, ReduceLROnPlateau, and ModelCheckpoint\n",
    "4) Slightly increase validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7558e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# add l2 regularization to conv layers(2)\n",
    "def build_regularized_model(hp):\n",
    "    input_layer = Input(shape=(200, 200, 3))\n",
    "    \n",
    "    l2_val = hp.Choice(\"l2_reg\", [1e-4, 5e-4])\n",
    "    x = Conv2D(32, (3,3), padding='same', kernel_regularizer=l2(l2_val))(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(2,2)(x)\n",
    "    \n",
    "    x = Conv2D(64, (3,3), padding='same', kernel_regularizer=l2(l2_val))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(2,2)(x)\n",
    "\n",
    "    x = Conv2D(128, (3,3), padding='same', kernel_regularizer=l2(l2_val))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(2,2)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    age_output = Dense(1, name='age_output')(x)\n",
    "    gender_output = Dense(2, activation='softmax', name='gender_output')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=[age_output, gender_output])\n",
    "    lr = hp.Choice('learning_rate', [0.0001, 0.0005, 0.001])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=lr),\n",
    "        loss={\n",
    "            'age_output': 'mse',\n",
    "            'gender_output': 'categorical_crossentropy'\n",
    "        },\n",
    "        metrics={\n",
    "            'age_output': 'mae',\n",
    "            'gender_output': 'accuracy'\n",
    "        }\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Create a tuner with joint objectives (1)\n",
    "tuner = kt.RandomSearch(\n",
    "    build_regularized_model,\n",
    "    objective= [\n",
    "        kt.Objective('val_age_output_mae', direction='min'),\n",
    "        kt.Objective('val_gender_output_accuracy', direction='max')\n",
    "    ],\n",
    "    max_trials=10,\n",
    "    overwrite=True,\n",
    "    directory='kt_search',\n",
    "    project_name='age_gender_cnn'\n",
    ")\n",
    "\n",
    "tuner.search(X_train, {'age_output': y_age_train, 'gender_output': y_gender_train}, epochs=4, validation_split=0.2)\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "print('Best learning rate:', tuner.get_best_hyperparameters(1)[0].get('learning_rate'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8bf50",
   "metadata": {},
   "source": [
    "#### 12. Building, Comiling & Training 2nd Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd881b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Add EarlyStopping (3)\n",
    "# Stop training if validation loss doesn't improve for 3 consecutive epochs\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',      # or 'val_age_output_mae', etc.\n",
    "    patience=3,              # number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # restore model weights from the epoch with the best value of the monitored quantity\n",
    ")\n",
    "\n",
    "# Add ReduceLROnPlateau (3)\n",
    "# Reduce learning rate when a metric has stopped improving\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=2, min_lr=1e-6, verbose=1\n",
    ")\n",
    "\n",
    "# Save the best model during training (3)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"best_age_gender.keras\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    verbose=1 # only log when a model is saved\n",
    ")\n",
    "\n",
    "history = best_model.fit(\n",
    "    X_train, {'age_output': y_age_train, 'gender_output': y_gender_train},\n",
    "    validation_split=0.2,\n",
    "    epochs=16,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop, lr_scheduler, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee01f613",
   "metadata": {},
   "source": [
    "#### üß† Training Improvements with Callbacks and Regularization\n",
    "\n",
    "1. Training Dynamics\n",
    "- Before, the training loss decreased steadily, but the **validation loss was unstable** and often spiked.  \n",
    "- With **EarlyStopping**, **ReduceLROnPlateau**, and **ModelCheckpoint**, the training process became **more controlled**:\n",
    "  - EarlyStopping prevented overtraining once validation stopped improving.  \n",
    "  - ReduceLROnPlateau automatically reduced the learning rate when a metric has stopped learning. \n",
    "  - ModelCheckpoint saved the best-performing model (based on validation loss), so I always kept the strongest version.\n",
    "\n",
    "2. Age Prediction (MAE)\n",
    "- Training MAE improved from **~8.5 ‚Üí 5.8** by the end.  \n",
    "- Validation MAE dropped and became more stable, hovering around **7.0‚Äì7.2** compared to ~9+ before.  \n",
    "- This shows the model is learning age features better and generalizing more consistently on unseen data.\n",
    "\n",
    "3. Gender Prediction (Accuracy)\n",
    "- Training gender accuracy improved to **94%+**, higher than previous runs.  \n",
    "- Validation gender accuracy consistently reached **~89‚Äì90%**, compared to ~86‚Äì87% earlier.  \n",
    "- The validation curve is smoother, showing that regularization + callbacks reduced overfitting.\n",
    "\n",
    "4. Loss Stability\n",
    "- Validation loss used to fluctuate heavily (sometimes >150).  \n",
    "- Now, it **dropped steadily to ~88‚Äì90**, with much smaller fluctuations.  \n",
    "- This demonstrates that learning rate scheduling helped the optimizer settle into better minima.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1dc4ce",
   "metadata": {},
   "source": [
    "#### 13. Evaluate on Test Set and Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8521afa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate(X_test, {'age_output': y_age_test, 'gender_output': y_gender_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dae9001",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(\"models/age_gender_model_2.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980b9c45",
   "metadata": {},
   "source": [
    "#### 14. Plot New Training vs Validation Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a37fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Age MAE\n",
    "plt.plot(history.history['age_output_mae'], label='Age MAE (Train)')\n",
    "plt.plot(history.history['val_age_output_mae'], label='Age MAE (Val)')\n",
    "plt.title('Age Prediction: Mean Absolute Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot Gender Accuracy\n",
    "plt.plot(history.history['gender_output_accuracy'], label='Gender Acc (Train)')\n",
    "plt.plot(history.history['val_gender_output_accuracy'], label='Gender Acc (Val)')\n",
    "plt.title('Gender Prediction: Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2ab854",
   "metadata": {},
   "source": [
    "#### üìä Training Results (After Regularization + Callbacks)\n",
    "\n",
    "1. Age Prediction (MAE)\n",
    "- **Training MAE** decreased steadily from ~8.5 ‚Üí 5.8, showing the model is learning age features effectively.  \n",
    "- **Validation MAE** fluctuated at the start but stabilized around ~7.0‚Äì7.2, much lower than earlier runs (~9+).  \n",
    "\n",
    "2. Gender Prediction (Accuracy)\n",
    "- **Training accuracy** increased smoothly from ~85% ‚Üí 94.5%.  \n",
    "- **Validation accuracy** climbed from ~74% ‚Üí ~90%, staying close to the training curve.   \n",
    "\n",
    "3. Key Takeaways\n",
    "- Both **age MAE** and **gender accuracy** improved compared to prior models. And the smaller gap between training and validation curves, and smoother validation curves indicates reduced overfitting and better generalization, hence with stabilized validation performance, the model was more robust for deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b320743b",
   "metadata": {},
   "source": [
    "#### 15. Age Prediction Evaluation - Predicted vs Actual Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get age predictions (output 0 from the model)\n",
    "y_pred_age = best_model.predict(X_test)[0].flatten()\n",
    "\n",
    "# Plot predicted vs actual ages\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_age_test, y_pred_age, alpha=0.5)\n",
    "plt.plot([0, 100], [0, 100], 'r--')  # ideal line\n",
    "plt.xlabel('Actual Age')\n",
    "plt.ylabel('Predicted Age')\n",
    "plt.title('Predicted vs Actual Age')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb367478",
   "metadata": {},
   "source": [
    "#### Insights:\n",
    "\n",
    "- ‚úÖ The model **successfully captures the age distribution trend** with relatively tight clustering along the ideal red line.\n",
    "- ‚úÖ A small mean absolute error (MAE) and this scatter pattern confirm that the model performs **reasonably well**.\n",
    "- ‚ö†Ô∏è - There are some outliers:\n",
    "  - A few predictions below 0 (can be fixed by clamping or using a `ReLU` in the output layer)\n",
    "  - More scatter and noise at age extremes (e.g. 60+), likely due to fewer samples in those ranges.\n",
    "\n",
    "> üéØ Overall, this visual confirms that my CNN is making **informed predictions** and not random guesses.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d8327",
   "metadata": {},
   "source": [
    "#### 16. Gender Prediction Evaluation ‚Äì Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f88c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Get gender predictions (output 1 from the model)\n",
    "y_pred_gender = best_model.predict(X_test)[1]\n",
    "\n",
    "# Convert one-hot encoded gender back to label\n",
    "y_pred_gender_labels = np.argmax(y_pred_gender, axis=1)\n",
    "y_true_gender_labels = np.argmax(y_gender_test, axis=1)\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_true_gender_labels, y_pred_gender_labels, target_names=['Male', 'Female']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6ca118",
   "metadata": {},
   "source": [
    "| Class   | Precision | Recall | F1-score | Support | \n",
    "|---------|-----------|--------|----------|---------|\n",
    "| Definition |Out of all the times the model predicted a class, how often was it correct?| Out of all the true samples of a class, how many did the model correctly identify?|  - | - |\n",
    "| Male    | 0.89      | 0.92   | 0.90     | 2320    |\n",
    "| Female  | 0.91      | 0.88   | 0.89     | 2163    |\n",
    "\n",
    "#### Insights:\n",
    "\n",
    "- ‚úÖ The model achieves a strong **90% overall accuracy** in gender classification.\n",
    "- ‚úÖ It‚Äôs especially strong at identifying **Male** samples (Recall: 92%), meaning it rarely misses when a sample is male.\n",
    "- ‚úÖ It is more precise when predicting **Female** (Precision: 91%), meaning when it says \"Female\", it's usually correct.\n",
    "\n",
    "> üéØ This confirms that my gender prediction performs well and makes reliable predictions for both classes with balanced precision and recall.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
